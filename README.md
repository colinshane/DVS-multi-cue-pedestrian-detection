# Multi-Cue Event Information Fusion for Pedestrian Detection with Neuromorphic Vision Sensors

## Introduction

We propose to develop pedestrian detectors that unlock the potential of the event data by leveraging multi-cue information and different fusion strategies.

To make the best out of the event data, we introduce three different event-stream encoding methods based on Frequency, Surface of Active Event (SAE) and Leaky Integrate-and-Fire (LIF). We further integrate them into the state-of-the-art neural network architectures with two fusion approaches: the channel-level fusion of the raw feature space and decision-level fusion with the probability assignments. We present a qualitative and quantitative explanation why different encoding methods are chosen to evaluate the pedestrian detection and which method performs the best.

## Algorithms

We promise that the code with algorithms involved in our paper will be made public here in this repository right after our paper is accepted and published.

## DVS-based Pedestrian Dataset

Based on our knowledge, no public labeled pedestrian dataset created with a neuromorphic vision sensor has already been published, so that we created one.

We promise that the dataset involved in our paper will be made public with a hyperlink here right after our paper is accepted and published.
